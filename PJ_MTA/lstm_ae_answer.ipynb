{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ” SWaT ë°ì´í„°ì…‹ LSTM-AE ê¸°ë°˜ ì´ìƒ íƒì§€ (Anomaly Detection)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ê°œìš”\n",
    "\n",
    "| í•­ëª© | ë‚´ìš© |\n",
    "|------|------|\n",
    "| **ë°ì´í„°ì…‹** | SWaT (Secure Water Treatment) - ì‹±ê°€í¬ë¥´ iTrust ì—°êµ¬ì†Œ |\n",
    "| **ëª¨ë¸** | LSTM-AE (Long Short-Term Memory Autoencoder) |\n",
    "| **ë°©ë²•** | ë¹„ì§€ë„ ì´ìƒ íƒì§€ - ì •ìƒ ë°ì´í„°ë¡œ í•™ìŠµ í›„ Reconstruction Error ê¸°ë°˜ íƒì§€ |\n",
    "| **í‰ê°€ì§€í‘œ** | Precision, Recall, F1-Score, AUC-ROC |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "```\n",
    "1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "2. ë°ì´í„° ë¡œë”©\n",
    "3. ë°ì´í„° ì „ì²˜ë¦¬ (ë‹¤ìš´ìƒ˜í”Œë§, ì •ê·œí™”, ì‹œí€€ìŠ¤ ìƒì„±)\n",
    "4. LSTM-AE ëª¨ë¸ ì •ì˜\n",
    "5. ëª¨ë¸ í•™ìŠµ\n",
    "6. ì´ìƒ íƒì§€ ë° í‰ê°€\n",
    "7. ê²°ê³¼ ì‹œê°í™”\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£ í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "\n",
    "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„í¬íŠ¸í•˜ê³  GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "# ============================================================\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ì „ì²˜ë¦¬ ë° í‰ê°€\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, precision_recall_curve, roc_curve,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ìœ í‹¸ë¦¬í‹°\n",
    "from tqdm.notebook import tqdm  # Jupyterìš© í”„ë¡œê·¸ë ˆìŠ¤ ë°”\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì‹œê°í™” ì„¤ì •\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: cuda\n",
      "   GPU ì´ë¦„: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "   GPU ë©”ëª¨ë¦¬: 6.44 GB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# GPU/CPU ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2ï¸âƒ£ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "\n",
    "ì „ì²˜ë¦¬, ëª¨ë¸, í•™ìŠµì— ì‚¬ìš©í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” íŒŒë¼ë¯¸í„° ì„¤ëª…\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ê¶Œì¥ê°’ |\n",
    "|----------|------|--------|\n",
    "| `downsample_rate` | ë°ì´í„° ì¶•ì†Œ ë¹„ìœ¨ (10 = 1/10) | 10~20 |\n",
    "| `window_size` | ì‹œí€€ìŠ¤ ê¸¸ì´ (íƒ€ì„ìŠ¤í… ìˆ˜) | 50~200 |\n",
    "| `stride` | ìœˆë„ìš° ì´ë™ ê°„ê²© | window_sizeì˜ 10~20% |\n",
    "| `hidden_dim` | LSTM ì€ë‹‰ì¸µ ì°¨ì› | 64~256 |\n",
    "| `latent_dim` | ì ì¬ ê³µê°„ ì°¨ì› | 32~128 |\n",
    "| `num_layers` | LSTM ë ˆì´ì–´ ìˆ˜ | 1~3 |\n",
    "| `threshold_percentile` | ì´ìƒ íŒì • ì„ê³„ê°’ ë°±ë¶„ìœ„ | 95~99 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •:\n",
      "==================================================\n",
      "  normal_data_path: /root/workspace/AEAD/Dataset/swat/normal.csv\n",
      "  attack_data_path: /root/workspace/AEAD/Dataset/swat/attack.csv\n",
      "  downsample_rate: 10\n",
      "  variance_threshold: 0.01\n",
      "  correlation_threshold: 0.95\n",
      "  window_size: 100\n",
      "  stride: 10\n",
      "  hidden_dim: 128\n",
      "  latent_dim: 64\n",
      "  num_layers: 2\n",
      "  dropout: 0.2\n",
      "  bidirectional: False\n",
      "  batch_size: 64\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  epochs: 100\n",
      "  patience: 10\n",
      "  threshold_percentile: 99.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # ----- ë°ì´í„° ê²½ë¡œ -----\n",
    "    'normal_data_path': './data/normal.csv',\n",
    "    'attack_data_path': './data/attack.csv',\n",
    "    \n",
    "    # ----- ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° -----\n",
    "    'downsample_rate': 10,        # ë‹¤ìš´ìƒ˜í”Œë§ ë¹„ìœ¨ (1ì´ˆ â†’ 10ì´ˆ)\n",
    "    'variance_threshold': 0.01,   # ì €ë¶„ì‚° ì»¬ëŸ¼ ì œê±° ì„ê³„ê°’\n",
    "    'correlation_threshold': 0.95, # ê³ ìƒê´€ ì»¬ëŸ¼ ì œê±° ì„ê³„ê°’\n",
    "    \n",
    "    # ----- ì‹œí€€ìŠ¤ íŒŒë¼ë¯¸í„° -----\n",
    "    'window_size': 100,  # ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "    'stride': 10,        # ìœˆë„ìš° ì´ë™ ê°„ê²©\n",
    "    \n",
    "    # ----- LSTM-AE ëª¨ë¸ íŒŒë¼ë¯¸í„° -----\n",
    "    'hidden_dim': 128,    # LSTM ì€ë‹‰ì¸µ ì°¨ì›\n",
    "    'latent_dim': 64,     # ì ì¬ ê³µê°„ ì°¨ì›\n",
    "    'num_layers': 2,      # LSTM ë ˆì´ì–´ ìˆ˜\n",
    "    'dropout': 0.2,       # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
    "    'bidirectional': False,  # ì–‘ë°©í–¥ LSTM ì‚¬ìš© ì—¬ë¶€\n",
    "    \n",
    "    # ----- í•™ìŠµ íŒŒë¼ë¯¸í„° -----\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-5,\n",
    "    'epochs': 100,\n",
    "    'patience': 10,  # Early Stopping\n",
    "    \n",
    "    # ----- ì´ìƒ íƒì§€ íŒŒë¼ë¯¸í„° -----\n",
    "    'threshold_percentile': 99.0  # ìƒìœ„ 1%ë¥¼ ì´ìƒìœ¼ë¡œ íŒì •\n",
    "}\n",
    "\n",
    "# ì„¤ì • ì¶œë ¥\n",
    "print(\"âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3ï¸âƒ£ ë°ì´í„° ë¡œë”©\n",
    "\n",
    "SWaT ë°ì´í„°ì…‹ì„ ë¡œë”©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ë°ì´í„°ì…‹ êµ¬ì„±\n",
    "\n",
    "| íŒŒì¼ | ì„¤ëª… | ë‚´ìš© |\n",
    "|------|------|------|\n",
    "| `normal.csv` | ì •ìƒ ìš´ì˜ ë°ì´í„° | 7ì¼ê°„ ì •ìƒ ìš´ì˜ ê¸°ë¡ |\n",
    "| `attack.csv` | ê³µê²© í¬í•¨ í…ŒìŠ¤íŠ¸ ë°ì´í„° | 4ì¼ê°„ 36ê°œ ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨ |\n",
    "\n",
    "### ì»¬ëŸ¼ êµ¬ì„± (51ê°œ ì„¼ì„œ + ë ˆì´ë¸”)\n",
    "- **FIT**: Flow meter\n",
    "- **LIT**: Level transmitter  \n",
    "- **AIT**: Analyzer indicator transmitter\n",
    "- **MV**: Motorized valve\n",
    "- **P**: Pump\n",
    "- **UV**: UV dechlorinator\n",
    "- **PIT**: Pressure indicator transmitter\n",
    "- **DPIT**: Differential pressure indicator transmitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...\n",
      "==================================================\n",
      "âœ… ì •ìƒ ë°ì´í„° ë¡œë”© ì™„ë£Œ: (1387098, 53)\n",
      "âœ… ê³µê²© ë°ì´í„° ë¡œë”© ì™„ë£Œ: (54621, 53)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì •ìƒ ë°ì´í„° ë¡œë”©\n",
    "normal_df = pd.read_csv(CONFIG['normal_data_path'], low_memory=False)\n",
    "print(f\"âœ… ì •ìƒ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {normal_df.shape}\")\n",
    "\n",
    "# ê³µê²© ë°ì´í„° ë¡œë”©\n",
    "attack_df = pd.read_csv(CONFIG['attack_data_path'], low_memory=False)\n",
    "print(f\"âœ… ê³µê²© ë°ì´í„° ë¡œë”© ì™„ë£Œ: {attack_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ì •ìƒ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>...</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "      <th>Normal/Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28/12/2015 10:00:00 AM</td>\n",
       "      <td>2.427057</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8652</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5988</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/12/2015 10:00:01 AM</td>\n",
       "      <td>2.446274</td>\n",
       "      <td>522.8860</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8652</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6789</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28/12/2015 10:00:02 AM</td>\n",
       "      <td>2.489191</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6789</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28/12/2015 10:00:03 AM</td>\n",
       "      <td>2.534350</td>\n",
       "      <td>522.9645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6148</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/12/2015 10:00:04 AM</td>\n",
       "      <td>2.569260</td>\n",
       "      <td>523.4748</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.443085</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5027</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp    FIT101    LIT101   MV101  P101  P102    AIT201  \\\n",
       "0   28/12/2015 10:00:00 AM  2.427057  522.8467     2.0     2     1  262.0161   \n",
       "1   28/12/2015 10:00:01 AM  2.446274  522.8860     2.0     2     1  262.0161   \n",
       "2   28/12/2015 10:00:02 AM  2.489191  522.8467     2.0     2     1  262.0161   \n",
       "3   28/12/2015 10:00:03 AM  2.534350  522.9645     2.0     2     1  262.0161   \n",
       "4   28/12/2015 10:00:04 AM  2.569260  523.4748     2.0     2     1  262.0161   \n",
       "\n",
       "     AIT202    AIT203    FIT201  ...  P501  P502    PIT501    PIT502  \\\n",
       "0  8.396437  328.6337  2.445391  ...     2     1  250.8652  1.649953   \n",
       "1  8.396437  328.6337  2.445391  ...     2     1  250.8652  1.649953   \n",
       "2  8.394514  328.6337  2.442316  ...     2     1  250.8812  1.649953   \n",
       "3  8.394514  328.6337  2.442316  ...     2     1  250.8812  1.649953   \n",
       "4  8.394514  328.6337  2.443085  ...     2     1  250.8812  1.649953   \n",
       "\n",
       "     PIT503    FIT601  P601  P602  P603  Normal/Attack  \n",
       "0  189.5988  0.000128     1     1     1         Normal  \n",
       "1  189.6789  0.000128     1     1     1         Normal  \n",
       "2  189.6789  0.000128     1     1     1         Normal  \n",
       "3  189.6148  0.000128     1     1     1         Normal  \n",
       "4  189.5027  0.000128     1     1     1         Normal  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ì •ìƒ ë°ì´í„° ê¸°ë³¸ ì •ë³´:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1387098 entries, 0 to 1387097\n",
      "Data columns (total 53 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0    Timestamp     1387098 non-null  object \n",
      " 1   FIT101         1387098 non-null  float64\n",
      " 2   LIT101         1387098 non-null  float64\n",
      " 3    MV101         395298 non-null   float64\n",
      " 4   P101           1387098 non-null  int64  \n",
      " 5   P102           1387098 non-null  int64  \n",
      " 6    AIT201        395298 non-null   float64\n",
      " 7   AIT202         1387098 non-null  float64\n",
      " 8   AIT203         1387098 non-null  float64\n",
      " 9   FIT201         1387098 non-null  float64\n",
      " 10   MV201         395298 non-null   float64\n",
      " 11   P201          395298 non-null   float64\n",
      " 12   P202          395298 non-null   float64\n",
      " 13  P203           1387098 non-null  int64  \n",
      " 14   P204          395298 non-null   float64\n",
      " 15  P205           1387098 non-null  int64  \n",
      " 16  P206           1387098 non-null  int64  \n",
      " 17  DPIT301        1387098 non-null  float64\n",
      " 18  FIT301         1387098 non-null  float64\n",
      " 19  LIT301         1387098 non-null  float64\n",
      " 20  MV301          1387098 non-null  int64  \n",
      " 21  MV302          1387098 non-null  int64  \n",
      " 22   MV303         395298 non-null   float64\n",
      " 23  MV304          1387098 non-null  int64  \n",
      " 24  P301           1387098 non-null  int64  \n",
      " 25  P302           1387098 non-null  int64  \n",
      " 26  AIT401         1387098 non-null  float64\n",
      " 27  AIT402         1387098 non-null  float64\n",
      " 28  FIT401         1387098 non-null  float64\n",
      " 29  LIT401         1387098 non-null  float64\n",
      " 30  P401           1387098 non-null  int64  \n",
      " 31  P402           1387098 non-null  int64  \n",
      " 32  P403           1387098 non-null  int64  \n",
      " 33  P404           1387098 non-null  int64  \n",
      " 34  UV401          1387098 non-null  int64  \n",
      " 35  AIT501         1387098 non-null  float64\n",
      " 36  AIT502         1387098 non-null  float64\n",
      " 37  AIT503         1387098 non-null  float64\n",
      " 38  AIT504         1387098 non-null  float64\n",
      " 39  FIT501         1387098 non-null  float64\n",
      " 40  FIT502         1387098 non-null  float64\n",
      " 41  FIT503         1387098 non-null  float64\n",
      " 42  FIT504         1387098 non-null  float64\n",
      " 43  P501           1387098 non-null  int64  \n",
      " 44  P502           1387098 non-null  int64  \n",
      " 45  PIT501         1387098 non-null  float64\n",
      " 46  PIT502         1387098 non-null  float64\n",
      " 47  PIT503         1387098 non-null  float64\n",
      " 48  FIT601         1387098 non-null  float64\n",
      " 49  P601           1387098 non-null  int64  \n",
      " 50  P602           1387098 non-null  int64  \n",
      " 51  P603           1387098 non-null  int64  \n",
      " 52  Normal/Attack  1387098 non-null  object \n",
      "dtypes: float64(31), int64(20), object(2)\n",
      "memory usage: 560.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ“Š ì •ìƒ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "display(normal_df.head())\n",
    "\n",
    "print(\"\\nğŸ“Š ì •ìƒ ë°ì´í„° ê¸°ë³¸ ì •ë³´:\")\n",
    "print(normal_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë ˆì´ë¸” ì¶”ì¶œ ì™„ë£Œ\n",
      "   - ì •ìƒ (0): 0\n",
      "   - ê³µê²© (1): 54621\n",
      "   - ê³µê²© ë¹„ìœ¨: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ì»¬ëŸ¼ëª… ì •ë¦¬ ë° ë ˆì´ë¸” ì¶”ì¶œ (SWaT ë°ì´í„°ì…‹ìš©)\n",
    "# ============================================================\n",
    "\n",
    "# ì»¬ëŸ¼ëª… ì •ë¦¬ (ê³µë°± ì œê±°)\n",
    "normal_df.columns = normal_df.columns.str.strip()\n",
    "attack_df.columns = attack_df.columns.str.strip()\n",
    "\n",
    "# ë ˆì´ë¸” ì»¬ëŸ¼ëª… í™•ì¸\n",
    "label_col = 'Normal/Attack'\n",
    "\n",
    "# ê³µê²© ë ˆì´ë¸” ì¶”ì¶œ ('Normal' â†’ 0, 'Attack' â†’ 1)\n",
    "attack_labels_raw = attack_df[label_col].str.strip().values\n",
    "attack_labels = (attack_labels_raw == 'Attack').astype(int)\n",
    "\n",
    "# ë ˆì´ë¸” ì»¬ëŸ¼ ì œê±°\n",
    "normal_df = normal_df.drop(columns=[label_col])\n",
    "attack_df = attack_df.drop(columns=[label_col])\n",
    "\n",
    "print(f\"âœ… ë ˆì´ë¸” ì¶”ì¶œ ì™„ë£Œ\")\n",
    "print(f\"   - ì •ìƒ (0): {np.sum(attack_labels == 0)}\")\n",
    "print(f\"   - ê³µê²© (1): {np.sum(attack_labels == 1)}\")\n",
    "print(f\"   - ê³µê²© ë¹„ìœ¨: {np.mean(attack_labels) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "### ì „ì²˜ë¦¬ ë‹¨ê³„\n",
    "\n",
    "1. **ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ**: Timestamp ë“± ë¹„ìˆ˜ì¹˜í˜• ì œê±°\n",
    "2. **ë‹¤ìš´ìƒ˜í”Œë§**: ë°ì´í„° í¬ê¸° ì¶•ì†Œ (1ì´ˆ â†’ 10ì´ˆ ê°„ê²©)\n",
    "3. **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**: ì „ë°©/í›„ë°© ì±„ì›€ + í‰ê· ê°’ ëŒ€ì²´\n",
    "4. **ì €ë¶„ì‚° ì»¬ëŸ¼ ì œê±°**: ë¶„ì‚°ì´ ê±°ì˜ 0ì¸ ì»¬ëŸ¼ ì œê±°\n",
    "5. **ê³ ìƒê´€ ì»¬ëŸ¼ ì œê±°**: ìƒê´€ê³„ìˆ˜ 0.95 ì´ìƒì¸ ì¤‘ë³µ ì»¬ëŸ¼ ì œê±°\n",
    "6. **ì •ê·œí™”**: MinMax Scaling (0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ ì™„ë£Œ: 51ê°œ ì»¬ëŸ¼\n",
      "   - ì •ìƒ ë°ì´í„°: (1387098, 51)\n",
      "   - ê³µê²© ë°ì´í„°: (54621, 51)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Step 1: ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "# ============================================================\n",
    "\n",
    "# ì œì™¸í•  ì»¬ëŸ¼ (ë¹„ìˆ˜ì¹˜í˜•) - SWaT ë°ì´í„°ì…‹ìš©\n",
    "exclude_cols = ['Timestamp']\n",
    "numeric_cols = [col for col in normal_df.columns if col not in exclude_cols]\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• ë°ì´í„° ì¶”ì¶œ\n",
    "normal_numeric = normal_df[numeric_cols].copy()\n",
    "attack_numeric = attack_df[[col for col in numeric_cols if col in attack_df.columns]].copy()\n",
    "\n",
    "# ê°•ì œ ìˆ˜ì¹˜í˜• ë³€í™˜ (ë¬¸ìì—´ â†’ ìˆ«ì, ë³€í™˜ ë¶ˆê°€ ì‹œ NaN)\n",
    "normal_numeric = normal_numeric.apply(pd.to_numeric, errors='coerce')\n",
    "attack_numeric = attack_numeric.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(f\"âœ… ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ ì™„ë£Œ: {len(numeric_cols)}ê°œ ì»¬ëŸ¼\")\n",
    "print(f\"   - ì •ìƒ ë°ì´í„°: {normal_numeric.shape}\")\n",
    "print(f\"   - ê³µê²© ë°ì´í„°: {attack_numeric.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë‹¤ìš´ìƒ˜í”Œë§ ì™„ë£Œ (1/10)\n",
      "   - ì •ìƒ ë°ì´í„°: (138710, 51)\n",
      "   - ê³µê²© ë°ì´í„°: (5463, 51)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Step 2: ë‹¤ìš´ìƒ˜í”Œë§\n",
    "# ============================================================\n",
    "\n",
    "downsample_rate = CONFIG['downsample_rate']\n",
    "\n",
    "# ë§¤ downsample_rate ë²ˆì§¸ í–‰ë§Œ ì„ íƒ\n",
    "normal_numeric = normal_numeric.iloc[::downsample_rate].reset_index(drop=True)\n",
    "attack_numeric = attack_numeric.iloc[::downsample_rate].reset_index(drop=True)\n",
    "\n",
    "# ë ˆì´ë¸”ë„ ë™ì¼í•˜ê²Œ ë‹¤ìš´ìƒ˜í”Œë§\n",
    "attack_labels = attack_labels[::downsample_rate]\n",
    "\n",
    "print(f\"âœ… ë‹¤ìš´ìƒ˜í”Œë§ ì™„ë£Œ (1/{downsample_rate})\")\n",
    "print(f\"   - ì •ìƒ ë°ì´í„°: {normal_numeric.shape}\")\n",
    "print(f\"   - ê³µê²© ë°ì´í„°: {attack_numeric.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ê²°ì¸¡ì¹˜ í˜„í™©:\n",
      "   - ì •ìƒ ë°ì´í„°: 694260ê°œ\n",
      "   - ê³µê²© ë°ì´í„°: 0ê°œ\n",
      "\n",
      "âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\n",
      "   - ìœ íš¨ ì»¬ëŸ¼ ìˆ˜: 51\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Step 3: ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "# ============================================================\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í˜„í™© í™•ì¸\n",
    "print(\"ğŸ“Š ê²°ì¸¡ì¹˜ í˜„í™©:\")\n",
    "print(f\"   - ì •ìƒ ë°ì´í„°: {normal_numeric.isna().sum().sum()}ê°œ\")\n",
    "print(f\"   - ê³µê²© ë°ì´í„°: {attack_numeric.isna().sum().sum()}ê°œ\")\n",
    "\n",
    "# ì „ë°©/í›„ë°© ì±„ì›€\n",
    "normal_numeric = normal_numeric.ffill().bfill()\n",
    "attack_numeric = attack_numeric.ffill().bfill()\n",
    "\n",
    "# ë‚¨ì€ NaNì€ ì»¬ëŸ¼ í‰ê· ìœ¼ë¡œ ëŒ€ì²´\n",
    "normal_numeric = normal_numeric.fillna(normal_numeric.mean())\n",
    "attack_numeric = attack_numeric.fillna(attack_numeric.mean())\n",
    "\n",
    "# ì „ì²´ê°€ NaNì¸ ì»¬ëŸ¼ ì œê±°\n",
    "valid_cols = normal_numeric.columns[~normal_numeric.isna().all()]\n",
    "normal_numeric = normal_numeric[valid_cols]\n",
    "attack_numeric = attack_numeric[[col for col in valid_cols if col in attack_numeric.columns]]\n",
    "\n",
    "print(f\"\\nâœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "print(f\"   - ìœ íš¨ ì»¬ëŸ¼ ìˆ˜: {len(valid_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ì €ë¶„ì‚° ì»¬ëŸ¼ ì œê±°:\n",
      "   - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: 20\n",
      "\n",
      "âœ… ì €ë¶„ì‚° ì»¬ëŸ¼ ì œê±° ì™„ë£Œ: 31ê°œ ì»¬ëŸ¼ ìœ ì§€\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Step 4: ì €ë¶„ì‚° ì»¬ëŸ¼ ì œê±°\n",
    "# ============================================================\n",
    "\n",
    "# ê° ì»¬ëŸ¼ì˜ ë¶„ì‚° ê³„ì‚°\n",
    "variances = normal_numeric.var()\n",
    "\n",
    "# ë¶„ì‚°ì´ ì„ê³„ê°’ ì´ìƒì¸ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "high_var_cols = variances[variances > CONFIG['variance_threshold']].index.tolist()\n",
    "\n",
    "# ì œê±°ëœ ì»¬ëŸ¼ í™•ì¸\n",
    "removed_cols = set(normal_numeric.columns) - set(high_var_cols)\n",
    "print(f\"ğŸ“Š ì €ë¶„ì‚° ì»¬ëŸ¼ ì œê±°:\")\n",
    "print(f\"   - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: {len(removed_cols)}\")\n",
    "if len(removed_cols) > 0 and len(removed_cols) <= 10:\n",
    "    print(f\"   - ì œê±°ëœ ì»¬ëŸ¼: {list(removed_cols)}\")\n",
    "\n",
    "# ì ìš©\n",
    "normal_numeric = normal_numeric[high_var_cols]\n",
    "attack_numeric = attack_numeric[[col for col in high_var_cols if col in attack_numeric.columns]]\n",
    "\n",
    "print(f\"\\nâœ… ì €ë¶„ì‚° ì»¬ëŸ¼ ì œê±° ì™„ë£Œ: {len(high_var_cols)}ê°œ ì»¬ëŸ¼ ìœ ì§€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ê³ ìƒê´€ ì»¬ëŸ¼ ì œê±°:\n",
      "   - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: 7\n",
      "âœ… ê³ ìƒê´€ ì»¬ëŸ¼ ì œê±° ì™„ë£Œ: 24ê°œ ì»¬ëŸ¼ ìœ ì§€\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Step 5: ê³ ìƒê´€ ì»¬ëŸ¼ ì œê±° (ì„ íƒì )\n",
    "# ============================================================\n",
    "\n",
    "if CONFIG['correlation_threshold'] < 1.0:\n",
    "    # ìƒê´€ í–‰ë ¬ ê³„ì‚°\n",
    "    corr_matrix = normal_numeric.corr().abs()\n",
    "    \n",
    "    # ìƒì‚¼ê° í–‰ë ¬ë§Œ ì‚¬ìš© (ì¤‘ë³µ ì œê±°)\n",
    "    upper = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    # ì„ê³„ê°’ ì´ìƒì˜ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ ì»¬ëŸ¼ ì°¾ê¸°\n",
    "    to_drop = [col for col in upper.columns \n",
    "               if any(upper[col] > CONFIG['correlation_threshold'])]\n",
    "    \n",
    "    print(f\"ğŸ“Š ê³ ìƒê´€ ì»¬ëŸ¼ ì œê±°:\")\n",
    "    print(f\"   - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: {len(to_drop)}\")\n",
    "    \n",
    "    # ì ìš©\n",
    "    normal_numeric = normal_numeric.drop(columns=to_drop)\n",
    "    attack_numeric = attack_numeric.drop(\n",
    "        columns=[col for col in to_drop if col in attack_numeric.columns]\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… ê³ ìƒê´€ ì»¬ëŸ¼ ì œê±° ì™„ë£Œ: {normal_numeric.shape[1]}ê°œ ì»¬ëŸ¼ ìœ ì§€\")\n",
    "else:\n",
    "    print(\"â­ï¸ ê³ ìƒê´€ ì»¬ëŸ¼ ì œê±° ê±´ë„ˆëœ€ (threshold=1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì •ê·œí™” ì™„ë£Œ (MinMax Scaling)\n",
      "\n",
      "ğŸ“Š ìµœì¢… ë°ì´í„° í¬ê¸°:\n",
      "   - ì •ìƒ ë°ì´í„°: (138710, 24)\n",
      "   - ê³µê²© ë°ì´í„°: (5463, 24)\n",
      "   - í”¼ì²˜ ìˆ˜: 24\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Step 6: ì •ê·œí™” (MinMax Scaling)\n",
    "# ============================================================\n",
    "\n",
    "# ì •ìƒ ë°ì´í„°ë¡œ ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ\n",
    "scaler = MinMaxScaler()\n",
    "normal_scaled = scaler.fit_transform(normal_numeric)\n",
    "\n",
    "# ê³µê²© ë°ì´í„°ì— ë™ì¼í•œ ìŠ¤ì¼€ì¼ëŸ¬ ì ìš©\n",
    "attack_scaled = scaler.transform(attack_numeric)\n",
    "\n",
    "# í”¼ì²˜ ì»¬ëŸ¼ëª… ì €ì¥\n",
    "feature_columns = normal_numeric.columns.tolist()\n",
    "n_features = len(feature_columns)\n",
    "\n",
    "print(f\"âœ… ì •ê·œí™” ì™„ë£Œ (MinMax Scaling)\")\n",
    "print(f\"\\nğŸ“Š ìµœì¢… ë°ì´í„° í¬ê¸°:\")\n",
    "print(f\"   - ì •ìƒ ë°ì´í„°: {normal_scaled.shape}\")\n",
    "print(f\"   - ê³µê²© ë°ì´í„°: {attack_scaled.shape}\")\n",
    "print(f\"   - í”¼ì²˜ ìˆ˜: {n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5ï¸âƒ£ ì‹œí€€ìŠ¤ ìƒì„± (Sliding Window)\n",
    "\n",
    "ì‹œê³„ì—´ ë°ì´í„°ë¥¼ LSTM-AE ëª¨ë¸ì— ì…ë ¥í•˜ê¸° ìœ„í•´ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì‹œí€€ìŠ¤ ìƒì„± ë°©ì‹\n",
    "\n",
    "```\n",
    "ì›ë³¸: [x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, ...]\n",
    "\n",
    "window_size=4, stride=2 ì¸ ê²½ìš°:\n",
    "  ì‹œí€€ìŠ¤ 1: [x1, x2, x3, x4]\n",
    "  ì‹œí€€ìŠ¤ 2: [x3, x4, x5, x6]\n",
    "  ì‹œí€€ìŠ¤ 3: [x5, x6, x7, x8]\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜\n",
    "# ============================================================\n",
    "\n",
    "def create_sequences(data, window_size, stride):\n",
    "    \"\"\"\n",
    "    ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        data: ì…ë ¥ ë°ì´í„° (samples, features)\n",
    "        window_size: ìœˆë„ìš° í¬ê¸° (ì‹œí€€ìŠ¤ ê¸¸ì´)\n",
    "        stride: ìœˆë„ìš° ì´ë™ ê°„ê²©\n",
    "        \n",
    "    Returns:\n",
    "        sequences: (num_sequences, window_size, features)\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for i in range(0, len(data) - window_size + 1, stride):\n",
    "        seq = data[i:i + window_size]\n",
    "        sequences.append(seq)\n",
    "    \n",
    "    return np.array(sequences)\n",
    "\n",
    "print(\"âœ… ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ì‹œí€€ìŠ¤ ìƒì„± ì„¤ì •:\n",
      "   - Window Size: 100\n",
      "   - Stride: 10\n",
      "\n",
      "ğŸ“Š ë°ì´í„° ë¶„í• :\n",
      "   - í•™ìŠµ ë°ì´í„°: (110968, 24)\n",
      "   - ê²€ì¦ ë°ì´í„°: (27742, 24)\n",
      "\n",
      "â³ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...\n",
      "\n",
      "âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ:\n",
      "   - í•™ìŠµ: (11087, 100, 24)\n",
      "   - ê²€ì¦: (2765, 100, 24)\n",
      "   - í…ŒìŠ¤íŠ¸: (537, 100, 24)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  ë° ì‹œí€€ìŠ¤ ìƒì„±\n",
    "# ============================================================\n",
    "\n",
    "window_size = CONFIG['window_size']\n",
    "stride = CONFIG['stride']\n",
    "\n",
    "print(f\"ğŸ“Š ì‹œí€€ìŠ¤ ìƒì„± ì„¤ì •:\")\n",
    "print(f\"   - Window Size: {window_size}\")\n",
    "print(f\"   - Stride: {stride}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ì •ìƒ ë°ì´í„°ì—ì„œ ë¯¸ë¦¬ í…ŒìŠ¤íŠ¸ìš© êµ¬ê°„ì„ ë–¼ì–´ë‚´ê¸°\n",
    "#  - normal_test: attack ë°ì´í„°ì™€ ë™ì¼í•œ ê¸¸ì´ë§Œí¼ ì‚¬ìš© (í´ë˜ìŠ¤ ë¹„ìœ¨ 1:1 ê°€ì •)\n",
    "#  - ë‚˜ë¨¸ì§€(normal_train_val)ë¥¼ ë‹¤ì‹œ train/valë¡œ ë¶„í• \n",
    "# ------------------------------------------------------------\n",
    "num_attack_samples = len(attack_scaled)\n",
    "\n",
    "if num_attack_samples >= len(normal_scaled):\n",
    "    raise ValueError(\n",
    "        f\"ê³µê²© ìƒ˜í”Œ ìˆ˜({num_attack_samples})ê°€ ì •ìƒ ìƒ˜í”Œ ìˆ˜({len(normal_scaled)})ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìŠµë‹ˆë‹¤. \" \n",
    "        \"normal_testë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. downsample_rate ë˜ëŠ” ë°ì´í„° ê¸¸ì´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "# ë’¤ì—ì„œë¶€í„° ê³µê²© ìƒ˜í”Œ ìˆ˜ì™€ ë™ì¼í•œ ê¸¸ì´ë§Œí¼ì„ í…ŒìŠ¤íŠ¸ìš© ì •ìƒ ë°ì´í„°ë¡œ ì‚¬ìš©\n",
    "normal_test = normal_scaled[-num_attack_samples:]\n",
    "normal_test_labels = np.zeros(len(normal_test), dtype=int)  # ëª¨ë‘ ì •ìƒ(0) ë¼ë²¨\n",
    "\n",
    "# ë‚˜ë¨¸ì§€ëŠ” í•™ìŠµ/ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš©\n",
    "normal_train_val = normal_scaled[:-num_attack_samples]\n",
    "\n",
    "train_size = int(len(normal_train_val) * 0.8)\n",
    "train_data = normal_train_val[:train_size]\n",
    "val_data = normal_train_val[train_size:]\n",
    "\n",
    "print(f\"\\nğŸ“Š ë°ì´í„° ë¶„í• :\")\n",
    "print(f\"   - ì „ì²´ ì •ìƒ ë°ì´í„°: {normal_scaled.shape}\")\n",
    "print(f\"   - í•™ìŠµìš© ì •ìƒ ë°ì´í„°: {train_data.shape}\")\n",
    "print(f\"   - ê²€ì¦ìš© ì •ìƒ ë°ì´í„°: {val_data.shape}\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ìš© ì •ìƒ ë°ì´í„°: {normal_test.shape}\")\n",
    "print(f\"   - ê³µê²© ë°ì´í„°(í…ŒìŠ¤íŠ¸ìš©): {attack_scaled.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ì‹œí€€ìŠ¤ ìƒì„±\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nâ³ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...\")\n",
    "\n",
    "train_sequences = create_sequences(train_data, window_size, stride)\n",
    "val_sequences = create_sequences(val_data, window_size, stride)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” [ì •ìƒ test + ê³µê²©]ì„ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì´ì–´ë¶™ì—¬ì„œ êµ¬ì„±\n",
    "test_data = np.concatenate([normal_test, attack_scaled], axis=0)\n",
    "\n",
    "# ì‹œí€€ìŠ¤ ìƒì„±\n",
    "test_sequences = create_sequences(test_data, window_size, stride)\n",
    "\n",
    "print(f\"\\nâœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ:\")\n",
    "print(f\"   - í•™ìŠµ: {train_sequences.shape}\")\n",
    "print(f\"   - ê²€ì¦: {val_sequences.shape}\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸: {test_sequences.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í…ŒìŠ¤íŠ¸ ë ˆì´ë¸” ìƒì„± ì™„ë£Œ:\n",
      "   - ì „ì²´ ì‹œí€€ìŠ¤: 537\n",
      "   - ì •ìƒ ì‹œí€€ìŠ¤: 0\n",
      "   - ê³µê²© ì‹œí€€ìŠ¤: 537\n",
      "   - ê³µê²© ë¹„ìœ¨: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# í…ŒìŠ¤íŠ¸ ë ˆì´ë¸” ìƒì„± (ìœˆë„ìš° ë‹¨ìœ„)\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ì›ì‹œ ì‹œê³„ì—´ ë‹¨ìœ„ ë¼ë²¨ ìƒì„±\n",
    "#  - normal_test êµ¬ê°„: ëª¨ë‘ ì •ìƒ(0)\n",
    "#  - attack êµ¬ê°„: ëª¨ë‘ ê³µê²©(1)ë¡œ ê°€ì •\n",
    "#    (SWaT attack.csvì—ëŠ” ë¹„ì •ìƒ êµ¬ê°„ë§Œ í¬í•¨ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)\n",
    "# ------------------------------------------------------------\n",
    "normal_test_labels = np.zeros(len(normal_test), dtype=int)\n",
    "attack_test_labels = np.ones(len(attack_scaled), dtype=int)\n",
    "\n",
    "test_labels_raw = np.concatenate([normal_test_labels, attack_test_labels])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ìœˆë„ìš° ë‹¨ìœ„ ë¼ë²¨ ìƒì„±\n",
    "#  - í•˜ë‚˜ì˜ ìœˆë„ìš°(window_size ê¸¸ì´)ì˜ í‰ê·  ë¼ë²¨ì´ 0.5 ì´ìƒì´ë©´ ê³µê²©(1)\n",
    "# ------------------------------------------------------------\n",
    "test_labels = []\n",
    "for i in range(0, len(test_labels_raw) - window_size + 1, stride):\n",
    "    window_labels = test_labels_raw[i:i + window_size]\n",
    "    test_labels.append(int(np.mean(window_labels) >= 0.5))\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ ë ˆì´ë¸” ìƒì„± ì™„ë£Œ:\")\n",
    "print(f\"   - ì „ì²´ ì‹œí€€ìŠ¤: {len(test_labels)}\")\n",
    "print(f\"   - ì •ìƒ ì‹œí€€ìŠ¤: {np.sum(test_labels == 0)}\")\n",
    "print(f\"   - ê³µê²© ì‹œí€€ìŠ¤: {np.sum(test_labels == 1)}\")\n",
    "print(f\"   - ê³µê²© ë¹„ìœ¨: {np.mean(test_labels) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataLoader ìƒì„± ì™„ë£Œ\n",
      "   - Batch Size: 64\n",
      "   - í•™ìŠµ ë°°ì¹˜ ìˆ˜: 174\n",
      "   - ê²€ì¦ ë°°ì¹˜ ìˆ˜: 44\n",
      "   - í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: 9\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PyTorch DataLoader ìƒì„±\n",
    "# ============================================================\n",
    "\n",
    "# Tensor ë³€í™˜\n",
    "train_tensor = torch.FloatTensor(train_sequences)\n",
    "val_tensor = torch.FloatTensor(val_sequences)\n",
    "test_tensor = torch.FloatTensor(test_sequences)\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "batch_size = CONFIG['batch_size']\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(train_tensor),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(val_tensor),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(test_tensor),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"âœ… DataLoader ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - Batch Size: {batch_size}\")\n",
    "print(f\"   - í•™ìŠµ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
    "print(f\"   - ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6ï¸âƒ£ LSTM-AE ëª¨ë¸ ì •ì˜\n",
    "\n",
    "### LSTM (Long Short-Term Memory) íŠ¹ì§•\n",
    "\n",
    "1. **ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµ**: ê²Œì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ì¥ê¸° ì‹œí€€ìŠ¤ íŒ¨í„´ í•™ìŠµ\n",
    "2. **Forget Gate**: ë¶ˆí•„ìš”í•œ ì •ë³´ ì‚­ì œ\n",
    "3. **Input Gate**: ìƒˆë¡œìš´ ì •ë³´ ì¶”ê°€\n",
    "4. **Output Gate**: ì¶œë ¥í•  ì •ë³´ ê²°ì •\n",
    "\n",
    "### ëª¨ë¸ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "Input (batch, seq_len, features)\n",
    "    â†“\n",
    "Encoder LSTM: features â†’ hidden_dim â†’ latent_dim\n",
    "    â†“\n",
    "Latent Vector (batch, latent_dim)\n",
    "    â†“\n",
    "Repeat Vector (batch, seq_len, latent_dim)\n",
    "    â†“\n",
    "Decoder LSTM: latent_dim â†’ hidden_dim â†’ features\n",
    "    â†“\n",
    "Output (batch, seq_len, features) - Reconstructed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LSTMEncoder ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LSTM Encoder\n",
    "# ============================================================\n",
    "\n",
    "class LSTMEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Encoder\n",
    "    \n",
    "    - ì‹œí€€ìŠ¤ë¥¼ ì ì¬ ê³µê°„ìœ¼ë¡œ ì••ì¶•\n",
    "    - ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ hidden stateë¥¼ ì ì¬ ë²¡í„°ë¡œ ì‚¬ìš©\n",
    "    \n",
    "    Args:\n",
    "        input_dim: ì…ë ¥ íŠ¹ì„± ìˆ˜\n",
    "        hidden_dim: LSTM ì€ë‹‰ì¸µ ì°¨ì›\n",
    "        latent_dim: ì ì¬ ê³µê°„ ì°¨ì›\n",
    "        num_layers: LSTM ë ˆì´ì–´ ìˆ˜\n",
    "        dropout: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
    "        bidirectional: ì–‘ë°©í–¥ LSTM ì‚¬ìš© ì—¬ë¶€\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=128, latent_dim=64, \n",
    "                 num_layers=2, dropout=0.2, bidirectional=False):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        \n",
    "        # LSTM ë ˆì´ì–´\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        # Hidden state â†’ Latent vector\n",
    "        self.fc = nn.Linear(hidden_dim * self.num_directions, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, seq_len, input_dim)\n",
    "        Returns:\n",
    "            latent: (batch, latent_dim)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # LSTM forward\n",
    "        # output: (batch, seq_len, hidden_dim * num_directions)\n",
    "        # h_n: (num_layers * num_directions, batch, hidden_dim)\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ hidden state ì‚¬ìš©\n",
    "        if self.bidirectional:\n",
    "            # ì–‘ë°©í–¥ì˜ ë§ˆì§€ë§‰ hidden state ì—°ê²°\n",
    "            h_forward = h_n[-2]  # ë§ˆì§€ë§‰ ë ˆì´ì–´ forward\n",
    "            h_backward = h_n[-1]  # ë§ˆì§€ë§‰ ë ˆì´ì–´ backward\n",
    "            h_last = torch.cat([h_forward, h_backward], dim=1)\n",
    "        else:\n",
    "            h_last = h_n[-1]  # (batch, hidden_dim)\n",
    "        \n",
    "        # Latent vector ìƒì„±\n",
    "        latent = self.fc(h_last)  # (batch, latent_dim)\n",
    "        \n",
    "        return latent\n",
    "\n",
    "print(\"âœ… LSTMEncoder ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LSTMDecoder ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LSTM Decoder\n",
    "# ============================================================\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Decoder\n",
    "    \n",
    "    - ì ì¬ ë²¡í„°ë¡œë¶€í„° ì›ë³¸ ì‹œí€€ìŠ¤ ë³µì›\n",
    "    - RepeatVectorë¡œ ì ì¬ ë²¡í„°ë¥¼ ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ ë°˜ë³µ\n",
    "    \n",
    "    Args:\n",
    "        latent_dim: ì ì¬ ê³µê°„ ì°¨ì›\n",
    "        hidden_dim: LSTM ì€ë‹‰ì¸µ ì°¨ì›\n",
    "        output_dim: ì¶œë ¥ íŠ¹ì„± ìˆ˜ (= ì…ë ¥ íŠ¹ì„± ìˆ˜)\n",
    "        seq_len: ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "        num_layers: LSTM ë ˆì´ì–´ ìˆ˜\n",
    "        dropout: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dim=128, output_dim=50, \n",
    "                 seq_len=100, num_layers=2, dropout=0.2):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Latent â†’ Hidden ë³€í™˜\n",
    "        self.fc_in = nn.Linear(latent_dim, hidden_dim)\n",
    "        \n",
    "        # LSTM ë ˆì´ì–´\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, latent):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            latent: (batch, latent_dim)\n",
    "        Returns:\n",
    "            output: (batch, seq_len, output_dim)\n",
    "        \"\"\"\n",
    "        batch_size = latent.size(0)\n",
    "        \n",
    "        # Latent â†’ Hidden ë³€í™˜\n",
    "        hidden_in = self.fc_in(latent)  # (batch, hidden_dim)\n",
    "        \n",
    "        # RepeatVector: ì ì¬ ë²¡í„°ë¥¼ seq_lenë§Œí¼ ë°˜ë³µ\n",
    "        repeated = hidden_in.unsqueeze(1).repeat(1, self.seq_len, 1)  # (batch, seq_len, hidden_dim)\n",
    "        \n",
    "        # LSTM forward\n",
    "        lstm_out, _ = self.lstm(repeated)  # (batch, seq_len, hidden_dim)\n",
    "        \n",
    "        # Output ìƒì„±\n",
    "        output = self.fc_out(lstm_out)  # (batch, seq_len, output_dim)\n",
    "        \n",
    "        return output\n",
    "\n",
    "print(\"âœ… LSTMDecoder ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LSTMAE ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LSTM Autoencoder (LSTM-AE)\n",
    "# ============================================================\n",
    "\n",
    "class LSTMAE(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Autoencoder\n",
    "    \n",
    "    ì´ìƒ íƒì§€ ì›ë¦¬:\n",
    "    - ì •ìƒ ë°ì´í„°ë¡œë§Œ í•™ìŠµ â†’ ì •ìƒ íŒ¨í„´ ì¬êµ¬ì„± ëŠ¥ë ¥ í•™ìŠµ\n",
    "    - ì´ìƒ ë°ì´í„°ëŠ” ì¬êµ¬ì„± ì˜¤ë¥˜(reconstruction error)ê°€ ë†’ìŒ\n",
    "    \n",
    "    Args:\n",
    "        input_dim: ì…ë ¥ íŠ¹ì„± ìˆ˜\n",
    "        hidden_dim: LSTM ì€ë‹‰ì¸µ ì°¨ì›\n",
    "        latent_dim: ì ì¬ ê³µê°„ ì°¨ì›\n",
    "        seq_len: ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "        num_layers: LSTM ë ˆì´ì–´ ìˆ˜\n",
    "        dropout: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
    "        bidirectional: ì¸ì½”ë” ì–‘ë°©í–¥ LSTM ì‚¬ìš© ì—¬ë¶€\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=128, latent_dim=64, \n",
    "                 seq_len=100, num_layers=2, dropout=0.2, bidirectional=False):\n",
    "        super(LSTMAE, self).__init__()\n",
    "        \n",
    "        self.encoder = LSTMEncoder(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        self.decoder = LSTMDecoder(\n",
    "            latent_dim=latent_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=input_dim,\n",
    "            seq_len=seq_len,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: ì…ë ¥ ì‹œí€€ìŠ¤ (batch, seq_len, features)\n",
    "        Returns:\n",
    "            reconstructed: ì¬êµ¬ì„±ëœ ì‹œí€€ìŠ¤ (batch, seq_len, features)\n",
    "        \"\"\"\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed\n",
    "    \n",
    "    def get_reconstruction_error(self, x):\n",
    "        \"\"\"ì¬êµ¬ì„± ì˜¤ë¥˜ ê³„ì‚°\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            reconstructed = self.forward(x)\n",
    "            # MSE per sample\n",
    "            error = torch.mean((x - reconstructed) ** 2, dim=(1, 2))\n",
    "        return error\n",
    "    \n",
    "    def get_latent(self, x):\n",
    "        \"\"\"ì ì¬ ë²¡í„° ì¶”ì¶œ\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            latent = self.encoder(x)\n",
    "        return latent\n",
    "\n",
    "print(\"âœ… LSTMAE ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°:\n",
      "============================================================\n",
      "LSTMAE(\n",
      "  (encoder): LSTMEncoder(\n",
      "    (lstm): LSTM(24, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
      "  )\n",
      "  (decoder): LSTMDecoder(\n",
      "    (fc_in): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (fc_out): Linear(in_features=128, out_features=24, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "ğŸ“Š íŒŒë¼ë¯¸í„° ìˆ˜:\n",
      "   - ì „ì²´: 494,808\n",
      "   - í•™ìŠµ ê°€ëŠ¥: 494,808\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "# ============================================================\n",
    "\n",
    "model = LSTMAE(\n",
    "    input_dim=n_features,\n",
    "    hidden_dim=CONFIG['hidden_dim'],\n",
    "    latent_dim=CONFIG['latent_dim'],\n",
    "    seq_len=CONFIG['window_size'],\n",
    "    num_layers=CONFIG['num_layers'],\n",
    "    dropout=CONFIG['dropout'],\n",
    "    bidirectional=CONFIG['bidirectional']\n",
    ").to(device)\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡° ì¶œë ¥\n",
    "print(\"ğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°:\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "\n",
    "# íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nğŸ“Š íŒŒë¼ë¯¸í„° ìˆ˜:\")\n",
    "print(f\"   - ì „ì²´: {total_params:,}\")\n",
    "print(f\"   - í•™ìŠµ ê°€ëŠ¥: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7ï¸âƒ£ ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "### í•™ìŠµ ì „ëµ\n",
    "\n",
    "- **ì†ì‹¤ í•¨ìˆ˜**: MSE (Mean Squared Error) - ì¬êµ¬ì„± ì†ì‹¤\n",
    "- **ì˜µí‹°ë§ˆì´ì €**: Adam with weight decay (L2 ì •ê·œí™”)\n",
    "- **Early Stopping**: ê²€ì¦ ì†ì‹¤ì´ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ\n",
    "- **Gradient Clipping**: ê·¸ë˜ë””ì–¸íŠ¸ í­ë°œ ë°©ì§€ (LSTMì—ì„œ íŠ¹íˆ ì¤‘ìš”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í•™ìŠµ ì„¤ì • ì™„ë£Œ\n",
      "   - ì†ì‹¤ í•¨ìˆ˜: MSELoss\n",
      "   - ì˜µí‹°ë§ˆì´ì €: Adam (lr=0.001, weight_decay=1e-05)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# í•™ìŠµ ì„¤ì •\n",
    "# ============================================================\n",
    "\n",
    "criterion = nn.MSELoss()  # ì¬êµ¬ì„± ì†ì‹¤\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ê¸°ë¡\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"âœ… í•™ìŠµ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"   - ì†ì‹¤ í•¨ìˆ˜: MSELoss\")\n",
    "print(f\"   - ì˜µí‹°ë§ˆì´ì €: Adam (lr={CONFIG['learning_rate']}, weight_decay={CONFIG['weight_decay']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í•™ìŠµ/ê²€ì¦ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# í•™ìŠµ í•¨ìˆ˜ ì •ì˜\n",
    "# ============================================================\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"í•œ ì—í­ í•™ìŠµ\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        x = batch[0].to(device)\n",
    "        \n",
    "        # Forward\n",
    "        reconstructed = model(x)\n",
    "        loss = criterion(reconstructed, x)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Clipping (LSTMì—ì„œ ì¤‘ìš”)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"ê²€ì¦ ì†ì‹¤ ê³„ì‚°\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x = batch[0].to(device)\n",
    "            reconstructed = model(x)\n",
    "            loss = criterion(reconstructed, x)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "print(\"âœ… í•™ìŠµ/ê²€ì¦ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘!\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c06731d6dd40aba0bad6be76dd15ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "epochs = CONFIG['epochs']\n",
    "patience = CONFIG['patience']\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    # í•™ìŠµ\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # ê²€ì¦\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Early Stopping ì²´í¬\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict().copy()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # ì§„í–‰ ìƒí™© ì¶œë ¥ (ë§¤ 10 ì—í­)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.6f}, \"\n",
    "              f\"Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "    # Early Stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nâ¹ï¸ Early Stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Best ëª¨ë¸ ë³µì›\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "print(f\"\\nâœ… í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"   - Best Validation Loss: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss', color='blue', linewidth=2)\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Train Loss', color='blue', linewidth=2)\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss (Log Scale)')\n",
    "plt.title('Learning Curve (Log Scale)')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('learning_curve_lstm.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ“Š í•™ìŠµ ê³¡ì„ ì´ 'learning_curve_lstm.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8ï¸âƒ£ ì´ìƒ íƒì§€ ë° í‰ê°€\n",
    "\n",
    "### ì´ìƒ íƒì§€ ì›ë¦¬\n",
    "\n",
    "1. ì •ìƒ ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ì€ **ì •ìƒ íŒ¨í„´**ì„ ì˜ ì¬êµ¬ì„±í•¨\n",
    "2. **ì´ìƒ ë°ì´í„°**ëŠ” í•™ìŠµí•˜ì§€ ì•Šì€ íŒ¨í„´ì´ë¯€ë¡œ ì¬êµ¬ì„± ì˜¤ë¥˜ê°€ ë†’ìŒ\n",
    "3. ì¬êµ¬ì„± ì˜¤ë¥˜ê°€ **ì„ê³„ê°’(threshold)** ì´ìƒì´ë©´ ì´ìƒìœ¼ë¡œ íŒì •\n",
    "\n",
    "### ì„ê³„ê°’ ê²°ì •\n",
    "\n",
    "ê²€ì¦ ë°ì´í„°(ì •ìƒ)ì˜ ì¬êµ¬ì„± ì˜¤ë¥˜ ë¶„í¬ì—ì„œ ìƒìœ„ 1% (99 percentile)ë¥¼ ì„ê³„ê°’ìœ¼ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ì´ìƒ ì ìˆ˜ (Reconstruction Error) ê³„ì‚° í•¨ìˆ˜\n",
    "# ============================================================\n",
    "\n",
    "def compute_anomaly_scores(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    ì´ìƒ ì ìˆ˜ ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        model: í•™ìŠµëœ LSTM-AE ëª¨ë¸\n",
    "        dataloader: ë°ì´í„° ë¡œë”\n",
    "        device: ë””ë°”ì´ìŠ¤\n",
    "        \n",
    "    Returns:\n",
    "        scores: ê° ìƒ˜í”Œì˜ ì¬êµ¬ì„± ì˜¤ë¥˜ (ì´ìƒ ì ìˆ˜)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x = batch[0].to(device)\n",
    "            scores = model.get_reconstruction_error(x)\n",
    "            all_scores.extend(scores.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_scores)\n",
    "\n",
    "print(\"âœ… ì´ìƒ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ì´ìƒ ì ìˆ˜ ê³„ì‚°\n",
    "# ============================================================\n",
    "\n",
    "print(\"â³ ì´ìƒ ì ìˆ˜ ê³„ì‚° ì¤‘...\")\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„° (ì •ìƒ)ì˜ ì´ìƒ ì ìˆ˜\n",
    "val_scores = compute_anomaly_scores(model, val_loader, device)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì´ìƒ ì ìˆ˜\n",
    "test_scores = compute_anomaly_scores(model, test_loader, device)\n",
    "\n",
    "print(f\"\\nâœ… ì´ìƒ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ\")\n",
    "print(f\"   - ê²€ì¦ ë°ì´í„° ì ìˆ˜: mean={np.mean(val_scores):.6f}, std={np.std(val_scores):.6f}\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ ë°ì´í„° ì ìˆ˜: mean={np.mean(test_scores):.6f}, std={np.std(test_scores):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ì„ê³„ê°’ ê²°ì •\n",
    "# ============================================================\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°(ì •ìƒ)ì˜ ìƒìœ„ percentileì„ ì„ê³„ê°’ìœ¼ë¡œ ì„¤ì •\n",
    "threshold = np.percentile(val_scores, CONFIG['threshold_percentile'])\n",
    "\n",
    "print(f\"ğŸ“Š ì„ê³„ê°’ ê²°ì •:\")\n",
    "print(f\"   - Percentile: {CONFIG['threshold_percentile']}%\")\n",
    "print(f\"   - Threshold: {threshold:.6f}\")\n",
    "\n",
    "# ë‹¤ì–‘í•œ percentile ê°’ í™•ì¸\n",
    "print(f\"\\n   ì°¸ê³  - ë‹¤ë¥¸ percentile ê°’:\")\n",
    "for p in [90, 95, 99, 99.5]:\n",
    "    print(f\"   - {p}%: {np.percentile(val_scores, p):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€\n",
    "# ============================================================\n",
    "\n",
    "# ì˜ˆì¸¡ (ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ ì´ìƒìœ¼ë¡œ íŒì •)\n",
    "predictions = (test_scores >= threshold).astype(int)\n",
    "\n",
    "# ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°\n",
    "precision = precision_score(test_labels, predictions, zero_division=0)\n",
    "recall = recall_score(test_labels, predictions, zero_division=0)\n",
    "f1 = f1_score(test_labels, predictions, zero_division=0)\n",
    "\n",
    "try:\n",
    "    auc_roc = roc_auc_score(test_labels, test_scores)\n",
    "except:\n",
    "    auc_roc = 0.0\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š ì´ìƒ íƒì§€ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nğŸ¯ ì£¼ìš” ì§€í‘œ:\")\n",
    "print(f\"   - Precision (ì •ë°€ë„): {precision:.4f}\")\n",
    "print(f\"   - Recall (ì¬í˜„ìœ¨):    {recall:.4f}\")\n",
    "print(f\"   - F1-Score:           {f1:.4f}\")\n",
    "print(f\"   - AUC-ROC:            {auc_roc:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Confusion Matrix:\")\n",
    "print(f\"                 Predicted\")\n",
    "print(f\"                 Normal  Attack\")\n",
    "print(f\"Actual Normal    {cm[0,0]:6d}  {cm[0,1]:6d}\")\n",
    "print(f\"Actual Attack    {cm[1,0]:6d}  {cm[1,1]:6d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ìƒì„¸ ë¶„ë¥˜ ë³´ê³ ì„œ\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nğŸ“‹ Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(test_labels, predictions, target_names=['Normal', 'Attack']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9ï¸âƒ£ ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "### ì‹œê°í™” í•­ëª©\n",
    "\n",
    "1. **ì´ìƒ ì ìˆ˜ ë¶„í¬**: ì •ìƒ vs ê³µê²© ë°ì´í„°ì˜ ì ìˆ˜ ë¶„í¬\n",
    "2. **ROC Curve**: True Positive Rate vs False Positive Rate\n",
    "3. **Precision-Recall Curve**: ì •ë°€ë„-ì¬í˜„ìœ¨ ê³¡ì„ \n",
    "4. **ì‹œê°„ë³„ ì´ìƒ ì ìˆ˜**: í…ŒìŠ¤íŠ¸ ê¸°ê°„ ë™ì•ˆì˜ ì´ìƒ ì ìˆ˜ ë³€í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ----- (1) ì´ìƒ ì ìˆ˜ ë¶„í¬ -----\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(val_scores, bins=50, alpha=0.7, label='Validation (Normal)', color='blue', density=True)\n",
    "ax1.hist(test_scores[test_labels == 0], bins=50, alpha=0.5, label='Test Normal', color='green', density=True)\n",
    "ax1.hist(test_scores[test_labels == 1], bins=50, alpha=0.5, label='Test Attack', color='red', density=True)\n",
    "ax1.axvline(threshold, color='black', linestyle='--', linewidth=2, label=f'Threshold: {threshold:.4f}')\n",
    "ax1.set_xlabel('Reconstruction Error (Anomaly Score)')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Anomaly Score Distribution')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ----- (2) ROC Curve -----\n",
    "ax2 = axes[0, 1]\n",
    "try:\n",
    "    fpr, tpr, _ = roc_curve(test_labels, test_scores)\n",
    "    ax2.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {auc_roc:.4f})')\n",
    "    ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('ROC Curve')\n",
    "    ax2.legend(loc='lower right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "except:\n",
    "    ax2.text(0.5, 0.5, 'ROC Curve unavailable', ha='center', va='center')\n",
    "\n",
    "# ----- (3) Precision-Recall Curve -----\n",
    "ax3 = axes[1, 0]\n",
    "try:\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(test_labels, test_scores)\n",
    "    ax3.plot(recall_curve, precision_curve, color='green', lw=2)\n",
    "    ax3.set_xlabel('Recall')\n",
    "    ax3.set_ylabel('Precision')\n",
    "    ax3.set_title('Precision-Recall Curve')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "except:\n",
    "    ax3.text(0.5, 0.5, 'PR Curve unavailable', ha='center', va='center')\n",
    "\n",
    "# ----- (4) ì‹œê°„ì— ë”°ë¥¸ ì´ìƒ ì ìˆ˜ -----\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(test_scores, alpha=0.7, linewidth=0.5, label='Anomaly Score', color='blue')\n",
    "ax4.axhline(threshold, color='red', linestyle='--', linewidth=2, label='Threshold')\n",
    "\n",
    "# ì‹¤ì œ ê³µê²© êµ¬ê°„ í‘œì‹œ\n",
    "attack_indices = np.where(test_labels == 1)[0]\n",
    "if len(attack_indices) > 0:\n",
    "    ax4.scatter(attack_indices, test_scores[attack_indices], \n",
    "               c='red', s=1, alpha=0.3, label='Attack Points')\n",
    "\n",
    "ax4.set_xlabel('Sample Index')\n",
    "ax4.set_ylabel('Anomaly Score')\n",
    "ax4.set_title('Anomaly Scores Over Time')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('anomaly_detection_results_lstm.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ“Š ê²°ê³¼ ê·¸ë˜í”„ê°€ 'anomaly_detection_results_lstm.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Confusion Matrix íˆíŠ¸ë§µ\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Normal', 'Attack'],\n",
    "            yticklabels=['Normal', 'Attack'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (LSTM-AE)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_lstm.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ“Š Confusion Matrixê°€ 'confusion_matrix_lstm.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ”Ÿ ëª¨ë¸ ì €ì¥\n",
    "\n",
    "í•™ìŠµëœ ëª¨ë¸ê³¼ ì„¤ì •ì„ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ëª¨ë¸ ì €ì¥\n",
    "# ============================================================\n",
    "\n",
    "save_dict = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'threshold': threshold,\n",
    "    'n_features': n_features,\n",
    "    'feature_columns': feature_columns,\n",
    "    'metrics': {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc_roc': auc_roc\n",
    "    },\n",
    "    'scaler_min': scaler.data_min_,\n",
    "    'scaler_max': scaler.data_max_\n",
    "}\n",
    "\n",
    "torch.save(save_dict, 'lstm_ae_swat_model.pth')\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ì´ 'lstm_ae_swat_model.pth'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"\\nğŸ“¦ ì €ì¥ëœ ë‚´ìš©:\")\n",
    "for key in save_dict.keys():\n",
    "    print(f\"   - {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ ìµœì¢… ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ìµœì¢… ê²°ê³¼ ìš”ì•½\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š SWaT LSTM-AE ì´ìƒ íƒì§€ - ìµœì¢… ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ”§ ë°ì´í„° ì„¤ì •:\")\n",
    "print(f\"   - ë‹¤ìš´ìƒ˜í”Œë§: 1/{CONFIG['downsample_rate']}\")\n",
    "print(f\"   - í”¼ì²˜ ìˆ˜: {n_features}\")\n",
    "print(f\"   - ìœˆë„ìš° í¬ê¸°: {CONFIG['window_size']}\")\n",
    "print(f\"   - Stride: {CONFIG['stride']}\")\n",
    "\n",
    "print(f\"\\nğŸ—ï¸ ëª¨ë¸ ì„¤ì •:\")\n",
    "print(f\"   - Hidden Dim: {CONFIG['hidden_dim']}\")\n",
    "print(f\"   - Latent Dim: {CONFIG['latent_dim']}\")\n",
    "print(f\"   - Num Layers: {CONFIG['num_layers']}\")\n",
    "print(f\"   - Dropout: {CONFIG['dropout']}\")\n",
    "print(f\"   - Bidirectional: {CONFIG['bidirectional']}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ í•™ìŠµ ê²°ê³¼:\")\n",
    "print(f\"   - ìµœì¢… í•™ìŠµ ì†ì‹¤: {train_losses[-1]:.6f}\")\n",
    "print(f\"   - ìµœì¢… ê²€ì¦ ì†ì‹¤: {val_losses[-1]:.6f}\")\n",
    "print(f\"   - Best ê²€ì¦ ì†ì‹¤: {best_val_loss:.6f}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì´ìƒ íƒì§€ ì„±ëŠ¥:\")\n",
    "print(f\"   - Threshold: {threshold:.6f}\")\n",
    "print(f\"   - Precision: {precision:.4f}\")\n",
    "print(f\"   - Recall: {recall:.4f}\")\n",
    "print(f\"   - F1-Score: {f1:.4f}\")\n",
    "print(f\"   - AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ”„ ì„±ëŠ¥ ê°œì„  ë°©ì•ˆ\n",
    "\n",
    "ì„±ëŠ¥ì´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì€ ê²½ìš° ë‹¤ìŒì„ ì‹œë„í•´ ë³´ì„¸ìš”:\n",
    "\n",
    "### í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "1. `window_size` ì¡°ì •: 50, 100, 200 ë“±\n",
    "2. `threshold_percentile` ì¡°ì •: 95, 97, 99 ë“±\n",
    "3. `hidden_dim` ì¡°ì •: 64, 128, 256 ë“±\n",
    "4. `latent_dim` ì¡°ì •: 32, 64, 128 ë“±\n",
    "5. `num_layers` ì¡°ì •: 1, 2, 3 ë“±\n",
    "6. `bidirectional` í™œì„±í™”: ì–‘ë°©í–¥ LSTM ì‚¬ìš©\n",
    "\n",
    "### ë°ì´í„° ì „ì²˜ë¦¬\n",
    "1. ë‹¤ìš´ìƒ˜í”Œë§ ë¹„ìœ¨ ì¡°ì •\n",
    "2. íŠ¹ì • ì„¼ì„œë§Œ ì„ íƒ\n",
    "3. ì´ë™ í‰ê·  ì ìš©\n",
    "\n",
    "### ëª¨ë¸ ì•„í‚¤í…ì²˜ ë³€í˜•\n",
    "1. GRU-AE ì‹œë„ (ë” ë¹ ë¥¸ í•™ìŠµ)\n",
    "2. Attention LSTM-AE ì‹œë„\n",
    "3. Variational LSTM-AE (LSTM-VAE) ì‹œë„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“š TCN-AE vs LSTM-AE ë¹„êµ\n",
    "\n",
    "| íŠ¹ì„± | TCN-AE | LSTM-AE |\n",
    "|------|--------|----------|\n",
    "| **ë³‘ë ¬í™”** | ë†’ìŒ (CNN ê¸°ë°˜) | ë‚®ìŒ (ìˆœì°¨ ì²˜ë¦¬) |\n",
    "| **í•™ìŠµ ì†ë„** | ë¹ ë¦„ | ëŠë¦¼ |\n",
    "| **ì¥ê¸° ì˜ì¡´ì„±** | Dilationìœ¼ë¡œ í™•ì¥ | ê²Œì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜ |\n",
    "| **ë©”ëª¨ë¦¬ ì‚¬ìš©** | ì ìŒ | ë§ìŒ |\n",
    "| **ê·¸ë˜ë””ì–¸íŠ¸ íë¦„** | ì•ˆì •ì  | ì†Œì‹¤/í­ë°œ ê°€ëŠ¥ |\n",
    "| **í•´ì„ ê°€ëŠ¥ì„±** | ìˆ˜ìš© ì˜ì—­ ëª…í™• | Hidden State ë¶„ì„ ê°€ëŠ¥ |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aead2_jupyter",
   "language": "python",
   "name": "aead2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
