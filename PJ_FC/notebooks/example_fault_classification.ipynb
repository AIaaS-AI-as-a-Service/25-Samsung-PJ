{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHM 데이터셋 고장 분류\n",
    "\n",
    "CNN-LSTM 모델을 사용하여 장비 고장 유형을 분류하는 실습 자료입니다.\n",
    "\n",
    "## 목표\n",
    "- 시계열 센서 데이터 전처리 방법 학습\n",
    "- 슬라이딩 윈도우 기법 이해 및 구현\n",
    "- CNN-LSTM 하이브리드 모델 구축\n",
    "- 고장 분류 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 전처리\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# 딥러닝\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# 시드 고정 (재현성)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 합성 데이터 생성\n",
    "\n",
    "실제 PHM 데이터셋을 사용할 수 없는 경우를 대비해 합성 데이터를 생성합니다.\n",
    "\n",
    "**Note**: 실제 프로젝트에서는 PHM Society Data Challenge에서 제공하는 실제 데이터를 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples=10000, n_sensors=10, n_fault_types=4):\n",
    "    \"\"\"\n",
    "    합성 PHM 센서 데이터 생성\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: 생성할 샘플 수\n",
    "    - n_sensors: 센서 개수\n",
    "    - n_fault_types: 고장 유형 수 (0: Normal, 1~3: Fault types)\n",
    "    \n",
    "    Returns:\n",
    "    - df: 생성된 데이터프레임\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hint: 각 고장 유형에 따라 다른 패턴을 가진 센서 데이터를 생성하세요\n",
    "    # Normal 데이터는 낮은 분산, Fault 데이터는 높은 분산 또는 트렌드를 가지도록 설정\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # TODO: 고장 유형을 무작위로 선택\n",
    "        fault_type = None  # 0 ~ n_fault_types-1 중 하나를 선택\n",
    "        \n",
    "        # TODO: 고장 유형에 따라 다른 특성을 가진 센서 데이터 생성\n",
    "        if fault_type == 0:  # Normal\n",
    "            # 정상 상태: 평균 근처의 작은 변동\n",
    "            sensor_data = None  # numpy를 사용하여 정규분포 데이터 생성\n",
    "        else:  # Fault\n",
    "            # 고장 상태: 더 큰 변동 또는 평균 shift\n",
    "            sensor_data = None  # 고장 유형에 따라 다른 패턴 생성\n",
    "        \n",
    "        # 데이터 저장\n",
    "        row = list(sensor_data) + [fault_type]\n",
    "        data.append(row)\n",
    "    \n",
    "    # 데이터프레임 생성\n",
    "    columns = [f'sensor_{i+1}' for i in range(n_sensors)] + ['fault_type']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 합성 데이터 생성 (실습용)\n",
    "# df = generate_synthetic_data(n_samples=10000, n_sensors=10, n_fault_types=4)\n",
    "\n",
    "# 실제 PHM 데이터를 사용하는 경우:\n",
    "# df = pd.read_csv('../data/raw/phm_data.csv')\n",
    "# PHM Society Data Challenge에서 다운로드한 데이터를 사용하세요\n",
    "\n",
    "print(\"데이터 생성 함수 정의 완료\")\n",
    "# print(f\"데이터 shape: {df.shape}\")\n",
    "# print(f\"\\n고장 유형 분포:\\n{df['fault_type'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 탐색 (EDA)\n",
    "\n",
    "**Hint**: 데이터의 분포, 고장 유형별 특성, 센서 간 상관관계 등을 시각화하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 데이터프레임의 기본 정보 확인\n",
    "# df.head(), df.info(), df.describe() 등을 활용\n",
    "\n",
    "# TODO: 고장 유형별 분포 시각화\n",
    "# plt.figure()를 사용하여 bar plot 생성\n",
    "\n",
    "# TODO: 센서 데이터의 분포 확인\n",
    "# 고장 유형별로 센서 값의 차이를 box plot 또는 histogram으로 시각화\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 전처리\n",
    "\n",
    "### 4.1 특징(X)과 타겟(y) 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 센서 데이터(X)와 고장 유형(y)을 분리\n",
    "# X = df.drop('fault_type', axis=1).values\n",
    "# y = df['fault_type'].values\n",
    "\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 데이터 정규화\n",
    "\n",
    "**Hint**: StandardScaler를 사용하여 각 센서 데이터를 정규화하세요. 이는 학습 속도와 성능을 향상시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: StandardScaler를 사용하여 데이터 정규화\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# print(f\"정규화 후 평균: {X_scaled.mean():.4f}\")\n",
    "# print(f\"정규화 후 표준편차: {X_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 슬라이딩 윈도우 생성\n",
    "\n",
    "시계열 데이터를 고정 길이의 윈도우로 분할합니다.\n",
    "\n",
    "**Hint**: \n",
    "- `window_size`: 한 샘플에 포함될 시간 스텝 수\n",
    "- `stride`: 윈도우를 이동시키는 간격\n",
    "- 각 윈도우의 마지막 시점의 레이블을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(X, y, window_size=100, stride=50):\n",
    "    \"\"\"\n",
    "    슬라이딩 윈도우를 사용하여 시계열 데이터를 변환\n",
    "    \n",
    "    Parameters:\n",
    "    - X: 입력 데이터 (n_samples, n_features)\n",
    "    - y: 레이블 (n_samples,)\n",
    "    - window_size: 윈도우 크기\n",
    "    - stride: 윈도우 이동 간격\n",
    "    \n",
    "    Returns:\n",
    "    - X_windows: (n_windows, window_size, n_features)\n",
    "    - y_windows: (n_windows,)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_windows = []\n",
    "    y_windows = []\n",
    "    \n",
    "    # TODO: 슬라이딩 윈도우 구현\n",
    "    # for 루프를 사용하여 stride 간격으로 윈도우를 생성\n",
    "    # 각 윈도우는 X[i:i+window_size]의 형태\n",
    "    # 레이블은 윈도우의 마지막 시점 y[i+window_size-1] 사용\n",
    "    \n",
    "    for i in range(0, len(X) - window_size + 1, stride):\n",
    "        # 윈도우 추출\n",
    "        window = None  # TODO: X에서 윈도우 크기만큼 슬라이싱\n",
    "        label = None   # TODO: 윈도우의 마지막 시점 레이블\n",
    "        \n",
    "        X_windows.append(window)\n",
    "        y_windows.append(label)\n",
    "    \n",
    "    # numpy array로 변환\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_windows = np.array(y_windows)\n",
    "    \n",
    "    return X_windows, y_windows\n",
    "\n",
    "# 윈도우 생성\n",
    "# window_size = 100\n",
    "# stride = 50\n",
    "\n",
    "# X_windows, y_windows = create_sliding_windows(X_scaled, y, window_size, stride)\n",
    "\n",
    "# print(f\"윈도우 데이터 shape: {X_windows.shape}\")\n",
    "# print(f\"윈도우 레이블 shape: {y_windows.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 One-hot Encoding\n",
    "\n",
    "**Hint**: to_categorical을 사용하여 레이블을 one-hot 벡터로 변환하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 레이블을 one-hot encoding으로 변환\n",
    "# y_categorical = to_categorical(y_windows)\n",
    "\n",
    "# print(f\"One-hot 레이블 shape: {y_categorical.shape}\")\n",
    "# print(f\"클래스 개수: {y_categorical.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 학습/테스트 데이터 분리 (80:20)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# print(f\"학습 데이터: {X_train.shape}, {y_train.shape}\")\n",
    "# print(f\"테스트 데이터: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CNN-LSTM 모델 구축\n",
    "\n",
    "### 모델 아키텍처\n",
    "1. **Conv1D**: 센서 간 공간적 특징 추출\n",
    "2. **LSTM**: 시간적 패턴 학습\n",
    "3. **Dense**: 분류\n",
    "\n",
    "**Hint**: \n",
    "- Input shape: (window_size, n_features)\n",
    "- Conv1D 레이어 후 MaxPooling 적용\n",
    "- LSTM 레이어는 return_sequences=False로 설정\n",
    "- 최종 Dense 레이어는 softmax 활성화 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_lstm_model(input_shape, n_classes):\n",
    "    \"\"\"\n",
    "    CNN-LSTM 모델 구축\n",
    "    \n",
    "    Parameters:\n",
    "    - input_shape: (window_size, n_features)\n",
    "    - n_classes: 분류할 클래스 개수\n",
    "    \n",
    "    Returns:\n",
    "    - model: Keras 모델\n",
    "    \"\"\"\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # TODO: CNN 레이어 추가\n",
    "    # Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape)\n",
    "    # MaxPooling1D(pool_size=2)\n",
    "    # Conv1D(filters=128, kernel_size=3, activation='relu')\n",
    "    # MaxPooling1D(pool_size=2)\n",
    "    \n",
    "    # TODO: LSTM 레이어 추가\n",
    "    # LSTM(units=100, return_sequences=False)\n",
    "    # Dropout(0.3) - 과적합 방지\n",
    "    \n",
    "    # TODO: Dense 레이어 추가\n",
    "    # Dense(units=50, activation='relu')\n",
    "    # Dropout(0.3)\n",
    "    # Dense(units=n_classes, activation='softmax')  # 최종 출력\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 모델 생성\n",
    "# input_shape = (window_size, X_scaled.shape[1])\n",
    "# n_classes = y_categorical.shape[1]\n",
    "\n",
    "# model = build_cnn_lstm_model(input_shape, n_classes)\n",
    "\n",
    "# TODO: 모델 컴파일\n",
    "# optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 학습\n",
    "\n",
    "**Hint**: \n",
    "- EarlyStopping: val_loss가 개선되지 않으면 조기 종료\n",
    "- ModelCheckpoint: 최고 성능 모델 저장\n",
    "- ReduceLROnPlateau: 학습률 동적 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 콜백 설정\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# model_checkpoint = ModelCheckpoint('../models/best_model.h5', save_best_only=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "\n",
    "# callbacks = [early_stopping, model_checkpoint, reduce_lr]\n",
    "\n",
    "# TODO: 모델 학습\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_split=0.2,\n",
    "#     epochs=50,\n",
    "#     batch_size=64,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 학습 곡선 시각화 (Loss와 Accuracy)\n",
    "# plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Subplot 1: Loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "# plt.legend(), plt.title('Loss'), plt.xlabel('Epoch'), plt.ylabel('Loss')\n",
    "\n",
    "# Subplot 2: Accuracy\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "# plt.legend(), plt.title('Accuracy'), plt.xlabel('Epoch'), plt.ylabel('Accuracy')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 모델 평가\n",
    "\n",
    "**Hint**: 테스트 데이터로 모델 성능을 평가하고, Confusion Matrix와 Classification Report를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 테스트 데이터로 예측\n",
    "# y_pred_prob = model.predict(X_test)\n",
    "# y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# TODO: 정확도 계산\n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "# print(f\"테스트 정확도: {accuracy:.4f}\")\n",
    "\n",
    "# TODO: Classification Report\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_true, y_pred, target_names=[f'Class {i}' for i in range(n_classes)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Confusion Matrix 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Confusion Matrix 계산 및 시각화\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 결과 분석 및 개선 방향\n",
    "\n",
    "**질문**:\n",
    "1. 모델의 성능이 만족스러운가요?\n",
    "2. 어떤 클래스가 가장 잘 분류되었나요?\n",
    "3. 어떤 클래스가 혼동되기 쉬운가요?\n",
    "4. 성능을 개선하기 위해 시도할 수 있는 방법은?\n",
    "   - 데이터 증강\n",
    "   - 하이퍼파라미터 튜닝 (window_size, stride, LSTM units, CNN filters)\n",
    "   - Attention mechanism 추가\n",
    "   - 클래스 불균형 처리 (class_weight, SMOTE)\n",
    "\n",
    "**실습 과제**:\n",
    "- 윈도우 크기를 변경해보고 성능 변화를 관찰하세요\n",
    "- LSTM units 수를 조정해보세요\n",
    "- 추가 Conv1D 레이어를 추가하거나 제거해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 추가 실험 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 최종 모델 저장\n",
    "# model.save('../models/final_cnn_lstm_model.h5')\n",
    "# print(\"모델 저장 완료\")\n",
    "\n",
    "# TODO: 모델 로드 (필요시)\n",
    "# loaded_model = keras.models.load_model('../models/final_cnn_lstm_model.h5')\n",
    "# print(\"모델 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 완료!\n",
    "\n",
    "수고하셨습니다. 이 노트북을 통해 CNN-LSTM 모델을 사용한 고장 분류의 전체 파이프라인을 학습하셨습니다.\n",
    "\n",
    "추가 학습을 위해 solution 노트북을 참고하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
